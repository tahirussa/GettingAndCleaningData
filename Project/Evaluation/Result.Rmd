Peer evaluations
================

Assignment
----------

> The purpose of this project is to demonstrate your ability to collect, work
> with, and clean a data set. The goal is to prepare tidy data that can be used
> for later analysis. You will be graded by your peers on a series of yes/no
> questions related to the project. You will be required to submit: 1) a tidy data
> set as described below, 2) a link to a Github repository with your script for
> performing the analysis, and 3) a code book that describes the variables, the
> data, and any transformations or work that you performed to clean up the data
> called CodeBook.md. You should also include a README.md in the repo with your
> scripts. This repo explains how all of the scripts work and how they are
> connected.
> 
> One of the most exciting areas in all of data science right now is wearable
> computing - see for example this article . Companies like Fitbit, Nike, and
> Jawbone Up are racing to develop the most advanced algorithms to attract new
> users. The data linked to from the course website represent data collected from
> the accelerometers from the Samsung Galaxy S smartphone. A full description is
> available at the site where the data was obtained:
> 
> http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 
> 
> Here are the data for the project: 
> 
> https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
> 
> You should create one R script called run_analysis.R that does the following.
> Merges the training and the test sets to create one data set. Extracts only the
> measurements on the mean and standard deviation for each measurement.  Uses
> descriptive activity names to name the activities in the data set Appropriately
> labels the data set with descriptive activity names.  Creates a second,
> independent tidy data set with the average of each variable for each activity
> and each subject.
> 
> Good luck!


Preliminaries
-------------

Load packages.

```{r}
packages <- c("data.table")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
```

Fix URL reading for knitr. See [Stackoverflow](http://stackoverflow.com/a/20003380).

```{r}
setInternet2(TRUE)
```


Grab datasets
-------------
My dataset. Use this to compare to peers. 

```{r}
f <- file.path("..", "DatasetHumanActivityRecognitionUsingSmartphones.txt")
d0 <- data.table(read.table(f, header=TRUE))
```

Student 1. 

```{r}
url <- "https://s3.amazonaws.com/coursera-uploads/user-da581c348504652cf6d52b48/972080/asst-3/320c2dc0ce3e11e3bb7387f31f11f941.txt"
d1 <- data.table(read.table(url, header=TRUE))
```

Student 2. 

```{r}
url <- "https://s3.amazonaws.com/coursera-uploads/user-cd5fa9234072b2113411a5b6/972080/asst-3/45e306b0ce6211e38f91f1adc287d0b7.txt"
d2 <- data.table(read.table(url, header=TRUE))
```

Student 3.

```{r}
url <- "https://s3.amazonaws.com/coursera-uploads/user-86e8069e2ecc3248b76506ff/972080/asst-3/b00980a0ce5d11e39688c70635ebeff0.txt"
d3 <- data.table(read.csv(url))
```

Student 4. 

```{r}
url <- "https://s3.amazonaws.com/coursera-uploads/user-bd605606b2bf83039906529c/972080/asst-3/1cf35bf0ce3b11e3a98a0101a16d1137.txt"
d4 <- data.table(read.table(url, header=TRUE))
```


GitHub repositories
-------------------

Student | URL
--------|----
Me      | https://github.com/benjamin-chan/GettingAndCleaningData/tree/master/Project
1       | https://github.com/sdrdis/getdata_peer_assessment
2       | https://github.com/alvasvoboda/PeerAssessment
3       | https://github.com/rafalohn/tidyData
4       | https://github.com/glynn/GACD_PeerAssessment


Compare dimensions of the datasets
----------------------------------

```{r}
dim0 <- sprintf("%.0d rows, %.0d columns", nrow(d0), ncol(d0))
dim1 <- sprintf("%.0d rows, %.0d columns", nrow(d1), ncol(d1))
dim2 <- sprintf("%.0d rows, %.0d columns", nrow(d2), ncol(d2))
dim3 <- sprintf("%.0d rows, %.0d columns", nrow(d3), ncol(d3))
dim4 <- sprintf("%.0d rows, %.0d columns", nrow(d4), ncol(d4))
```


Student | Dimensions of tidy dataset
--------|---------------------------
Me      | `r dim0`
1       | `r dim1`
2       | `r dim2`
3       | `r dim3`
4       | `r dim4`


Variables in each dataset
-------------------------

```{r}
names(d0)
names(d1)
names(d2)
names(d3)
names(d4)
```


Examine factor class variables
------------------------------

```{r}
sapply(d0[, sapply(d0, is.factor), with=FALSE], levels)
sapply(d1[, sapply(d1, is.factor), with=FALSE], levels)
sapply(d2[, sapply(d2, is.factor), with=FALSE], levels)
sapply(d3[, sapply(d3, is.factor), with=FALSE], levels)
sapply(d4[, sapply(d4, is.factor), with=FALSE], levels)
```


Find a particular value
-----------------------
Find record for

* Subject: 1
* Activity: laying
* Domain: time
* Acceleration: body
* Instrument: accelerometer
* Jerk: NA
* Magnitude: NA
* Variable: mean
* Axis: X

```{r}
d0[subject == 1 & activity == "LAYING" & featDomain == "Time" & featAcceleration == "Body" & featInstrument == "Accelerometer" & is.na(featJerk) & is.na(featMagnitude) & featVariable == "Mean" & featAxis == "X"]
d1[, tBodyAcc.mean.X]
d2[subject_id == 1, list(subject_id, y_label, tBodyAcc_mean_X)]
d3[X == "tBodyAcc-mean()-X", list(X, X1.LAYING)]
d4[subject.id == 1 & activity == "LAYING", list(subject.id, activity, tBodyAcc.mean...X)]
```

For Student 1 and 2's tidy datasets, it's impossible to isolate the required record using the variables within the respective datasets.


Sample observations in each dataset
-----------------------------------

```{r}
head(d0)
head(d1)
head(d2)
head(d3)
head(d4)
```
